{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is an implementation of Quantile-Sketch Normalization on given dataset. \n",
    "\n",
    "### The aim of this normalization technique is to run machine learning algorithms on a smaller part of the dataset after normalizing the dataset values to a certain scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SIZE = 22810\n",
    "N = MAX_SIZE//10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose N random indices from a range of MAX_SIZE numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "probes = sorted(random.sample(range(MAX_SIZE), N))\n",
    "# print(probes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the lists of dataframes that must be concatenated for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_val, list_det = [], []\n",
    "list_abs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining some helper functions for further usage in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_table(tbl):\n",
    "    print(\"-----------------------------------------------------------------------------------\")\n",
    "    print(tbl.head())\n",
    "    print(\"-----------------------------------------------------------------------------------\")\n",
    "    \n",
    "def table_to_csv(tbl, csv_filename):\n",
    "    tbl.to_csv(csv_filename)\n",
    "    print(\"Created the file:\",csv_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening the file that contains the path to the dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = open('listfile_quantile','r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading each file and making separate dataframes for each feature for the sake of applying normalization calculus on them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_-_-_-_-_- Reading the file 'Dataset_new/GSM6577.txt'_-_-_-_-_\n",
      "_-_-_-_-_- Reading the file 'Dataset_new/GSM6578.txt'_-_-_-_-_\n",
      "_-_-_-_-_- Reading the file 'Dataset_new/GSM6579.txt'_-_-_-_-_\n",
      "_-_-_-_-_- Reading the file 'Dataset_new/GSM6580.txt'_-_-_-_-_\n",
      "_-_-_-_-_- Reading the file 'Dataset_new/GSM6581.txt'_-_-_-_-_\n",
      "_-_-_-_-_- Reading the file 'Dataset_new/GSM6582.txt'_-_-_-_-_\n",
      "_-_-_-_-_- Reading the file 'Dataset_new/GSM6583.txt'_-_-_-_-_\n",
      "_-_-_-_-_- Reading the file 'Dataset_new/GSM6584.txt'_-_-_-_-_\n",
      "_-_-_-_-_- Reading the file 'Dataset_new/GSM6227.txt'_-_-_-_-_\n",
      "_-_-_-_-_- Reading the file 'Dataset_new/GSM6544.txt'_-_-_-_-_\n",
      "_-_-_-_-_- Reading the file 'Dataset_new/GSM6571.txt'_-_-_-_-_\n",
      "_-_-_-_-_- Reading the file 'Dataset_new/GSM6572.txt'_-_-_-_-_\n",
      "_-_-_-_-_- Reading the file 'Dataset_new/GSM6573.txt'_-_-_-_-_\n",
      "_-_-_-_-_- Reading the file 'Dataset_new/GSM6574.txt'_-_-_-_-_\n",
      "_-_-_-_-_- Reading the file 'Dataset_new/GSM6575.txt'_-_-_-_-_\n",
      "_-_-_-_-_- Reading the file 'Dataset_new/GSM6576.txt'_-_-_-_-_\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for file in files:\n",
    "    file = file.strip('\\n')\n",
    "    print(\"_-_-_-_-_- Reading the file '{}'_-_-_-_-_\".format(file))\n",
    "\n",
    "    ## read CSV from text file\n",
    "    df = pd.read_csv(file, sep='\\t')\n",
    "\n",
    "    ## choosing only the N randomly chosen row values of the 'VALUE' feature\n",
    "    df_val = df[['ID_REF','VALUE']].iloc[probes]\n",
    "    df_val.columns = ['ID_REF', file[-11:-4]+'_A']\n",
    "    # preview_table(df_val)\n",
    "    \n",
    "    ## appending the 'VALUE' column of each file to the list of dataframes \n",
    "    list_val.append(df_val)\n",
    "\n",
    "    \n",
    "    \n",
    "    ## choosing only the N randomly chosen row values of the 'Detection p-value' feature\n",
    "    df_det = df[['ID_REF','Detection p-value']].iloc[probes]\n",
    "    df_det.columns = ['ID_REF', file[-11:-4]+'_B']\n",
    "    # preview_table(df_det)\n",
    "\n",
    "    ## appending the 'Detection p-value' column of each file to the list of dataframes \n",
    "    list_det.append(df_det)\n",
    "\n",
    "    \n",
    "    \n",
    "    ## choosing only the N randomly chosen row values of the 'ABS_CALL' feature\n",
    "    df_abs = df[['ID_REF','ABS_CALL']].iloc[probes]\n",
    "    df_abs.columns = ['ID_REF', file[-11:-4]+'_C']\n",
    "    # preview_table(df_abs)\n",
    "    \n",
    "    ## appending the 'ABS_CALL' column of each file to the list of dataframes \n",
    "    list_abs.append(df_abs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to convert the list into a table and making the necessary feature-tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the file: table_val.csv\n",
      "Created the file: table_det.csv\n"
     ]
    }
   ],
   "source": [
    "def make_table(l):\n",
    "    ## concatenating the list of dataframes into a single table\n",
    "    tbl = pd.concat(l, axis=1)\n",
    "\n",
    "    ## eliminating any duplicate columns in the table\n",
    "    tbl = tbl.loc[:, ~tbl.columns.duplicated()]\n",
    "    \n",
    "    # preview_table(tbl)\n",
    "    return tbl\n",
    "\n",
    "\n",
    "table_val = make_table(list_val)\n",
    "table_to_csv(table_val, 'table_val.csv')\n",
    "table_det = make_table(list_det)\n",
    "table_to_csv(table_det, 'table_det.csv')\n",
    "table_abs = make_table(list_abs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to implement quantile normalization and calling them on the necessary feature-tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the file: normalized_val.csv\n",
      "Created the file: normalized_det.csv\n"
     ]
    }
   ],
   "source": [
    "def normalize(table):\n",
    "    sorted_tbl = table['ID_REF'].to_frame()\n",
    "    \n",
    "    ## sorting all the values column-wise\n",
    "    for c in table.columns[1:]:\n",
    "        sorted_tbl[c] = sorted(list(table[c]))\n",
    "    # preview_table(sorted_tbl)\n",
    "    \n",
    "    ## finding the row-wise means of the sorted table\n",
    "    ## and assigning them to their respective ranks\n",
    "    rank_vals = sorted_tbl.mean(axis=1).reset_index().drop(['index'], axis=1)\n",
    "    # table_to_csv(rank_vals, 'rank_vals.csv')\n",
    "    \n",
    "    ## converting the ranks table into a dictionary\n",
    "    ranks_dict = rank_vals.to_dict()[0]\n",
    "    # print(ranks_dict)\n",
    "\n",
    "    ## making the column-wise ranks table of the original dataset\n",
    "    normalized_tbl = table['ID_REF'].to_frame()\n",
    "    normalized_tbl[table.columns[1:]] = table[table.columns[1:]].rank(method='min')\n",
    "    # preview_table(normalized_tbl)    \n",
    "\n",
    "    ## replacing the rank in each cell with its \n",
    "    ## corresponding calculated mean value\n",
    "    for i in range(len(normalized_tbl)):\n",
    "        for j in range(1,len(normalized_tbl.columns)):\n",
    "            temp = normalized_tbl.iat[i,j]\n",
    "            temp = ranks_dict[int(temp)-1]\n",
    "            normalized_tbl.iat[i,j] = temp\n",
    "            \n",
    "    # preview_table(normalized_tbl)    \n",
    "    return normalized_tbl\n",
    "\n",
    "normalized_val = normalize(table_val)\n",
    "table_to_csv(normalized_val, 'normalized_val.csv')\n",
    "\n",
    "normalized_det = normalize(table_det)\n",
    "table_to_csv(normalized_det, 'normalized_det.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the preprocessed and normalized dataset, we now move on to classifying the model to predict the 'ABS_CALL' label when the features 'VALUE' and 'Detection p-value' are provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the file: X_train.csv\n",
      "Created the file: y_train.csv\n"
     ]
    }
   ],
   "source": [
    "list_X_train, list_y_train = [], []\n",
    "for i in range(1, len(table_abs.columns)-1):\n",
    "    ## appending the normalized feature vectors to the list of dataframes\n",
    "    dfX = pd.concat([normalized_val.iloc[:,[0,i]],normalized_det.iloc[:,i]], axis=1)\n",
    "    dfX.columns = ['ID_REF', 'VALUE', 'Detection p-value']\n",
    "    list_X_train.append(dfX)\n",
    "\n",
    "    ## appending the target vectors to the list of dataframes\n",
    "    dfy = table_abs.iloc[:,i]\n",
    "    dfy.columns = ['ABS_CALL']\n",
    "    list_y_train.append(dfy)\n",
    "# print(len(list_X_train), len(list_y_train))\n",
    "\n",
    "## concatenating the list of dataframes of \n",
    "## the features into a single table\n",
    "X_train = pd.concat(list_X_train)\n",
    "table_to_csv(X_train, 'X_train.csv')\n",
    "# preview_table(X_train)\n",
    "\n",
    "## concatenating the list of dataframes of \n",
    "## target vectors into a single table\n",
    "y_train = pd.concat(list_y_train)\n",
    "table_to_csv(y_train, 'y_train.csv')\n",
    "# preview_table(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the testing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the file: X_test.csv\n",
      "Created the file: y_test.csv\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('Dataset_new/GSM6576.txt', sep='\\t')\n",
    "X_test, y_test = df_test.iloc[:,[0,1,3]],df_test.iloc[:,2]\n",
    "table_to_csv(X_test, 'X_test.csv')\n",
    "table_to_csv(y_test, 'y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label encoding the feature vectors in string format into float format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "X_train['ID_REF'] = le.fit_transform(X_train['ID_REF'])\n",
    "y_train = le.fit_transform(y_train)\n",
    "\n",
    "X_test['ID_REF'] = le.fit_transform(X_test['ID_REF'])\n",
    "y_test = le.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training our model with the Gaussian Naive Bayes Classifier algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the class labels on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating our classifier model by making a confusion matrix of the predicted and actual target values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7910,    21,  1691],\n",
       "       [   72,     4,   243],\n",
       "       [  378,     1, 12490]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the accuracy of the classifier model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  89.4519947391495 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "print (\"Accuracy : \", accuracy_score(y_test,y_pred)*100,'%','\\n') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
